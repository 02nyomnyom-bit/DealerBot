# backup_cog.py
from __future__ import annotations
import os
import zipfile
import logging
import threading
import time
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import traceback
from discord.ext import commands

# âœ… ë°±ì—… ì„¤ì •
BACKUP_CONFIG = {
    "backup_interval_hours": 6,
    "max_backups": 30,
    "compress": True,
    "verify_backups": True,
    "backup_on_startup": True,
    "exclude_patterns": [
        "*.tmp", "*.temp", "__pycache__", "*.pyc"
    ],
    "source_files": [
        "data/dotori_bot.db",
        "data/point_data.json",
        "data/voice_time_data.json",
        "data/xp_leaderboard.json",
        "data/levelup_channels.json",
        "data/xp_settings.json"
    ]
}

# âœ… ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì „ìš© ë¡œê¹… ì„¤ì •"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logger = logging.getLogger("database_manager")
    logger.setLevel(logging.INFO)
    
    if not logger.handlers:
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        file_handler = logging.FileHandler(log_dir / 'database.log', encoding='utf-8')
        file_handler.setFormatter(formatter)
        file_handler.setLevel(logging.INFO)
        logger.addHandler(file_handler)
        
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(logging.INFO)
        logger.addHandler(console_handler)
        
    return logger

logger = setup_logging()

# âœ… ë°±ì—… ì‹œìŠ¤í…œ í´ë˜ìŠ¤
class BackupSystem:
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or BACKUP_CONFIG
        self.logger = setup_logging()
        self.base_dir = Path(os.getcwd())
        self.backup_dir = self.base_dir / 'backups'
        self.config_file = self.base_dir / 'backup_config.json'
        
        self.source_files = [self.base_dir / f for f in self.config.get('source_files', [])]

        self.backup_dir.mkdir(exist_ok=True)
        self.is_running = False
        
        self.running = False
        self.backup_thread = None
        self.scheduler_thread = None
        
        self.stats = {
            "total_backups": 0,
            "successful_backups": 0,
            "failed_backups": 0,
            "last_backup_time": None,
            "last_backup_size": 0
        }
        
        self.logger.info("ğŸ›¡ï¸ ë°±ì—… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
    def _load_config(self) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            if self.config_file.exists():
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    loaded_config = json.load(f)
                return {**BACKUP_CONFIG, **loaded_config}
            else:
                self._save_config(BACKUP_CONFIG)
                return BACKUP_CONFIG.copy()
        except Exception as e:
            self.logger.error(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return BACKUP_CONFIG.copy()
            
    def _save_config(self, config: Dict = None) -> bool:
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            config_to_save = config or self.config
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config_to_save, f, indent=4, ensure_ascii=False)
            return True
        except Exception as e:
            self.logger.error(f"ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
            
    def create_backup(self, backup_name: Optional[str] = None) -> Tuple[bool, str]:
        """ë°±ì—… ìƒì„±"""
        try:
            self.stats["total_backups"] += 1
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{backup_name}_{timestamp}.zip" if backup_name else f"backup_{timestamp}.zip"
            backup_path = self.backup_dir / filename
            
            self.logger.info(f"ë°±ì—… ìƒì„± ì‹œì‘: {filename}")
            
            files_to_backup = [f for f in self.source_files if f.exists()]
            if not files_to_backup:
                self.stats["failed_backups"] += 1
                return False, "ë°±ì—…í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                backup_info = {
                    "timestamp": datetime.now().isoformat(),
                    "backup_type": "manual" if backup_name else "auto",
                    "backup_version": "2.0",
                    "total_files": len(files_to_backup),
                    "files": [str(f) for f in files_to_backup]
                }
                zipf.writestr("backup_info.json", json.dumps(backup_info, indent=2))
                
                for file_path in files_to_backup:
                    try:
                        zipf.write(file_path, file_path)
                        self.logger.info(f"íŒŒì¼ ì¶”ê°€ ì™„ë£Œ: {file_path}")
                    except Exception as e:
                        self.logger.error(f"íŒŒì¼ ì¶”ê°€ ì‹¤íŒ¨: {file_path} - {e}")
            
            if self.config.get("verify_backups", True):
                if not self._verify_backup(str(backup_path), [str(f) for f in files_to_backup]):
                    self.stats["failed_backups"] += 1
                    return False, "ë°±ì—… ê²€ì¦ ì‹¤íŒ¨"
            
            backup_size = backup_path.stat().st_size
            self.stats["successful_backups"] += 1
            self.stats["last_backup_time"] = datetime.now().isoformat()
            self.stats["last_backup_size"] = backup_size
            
            self.cleanup_old_backups()
            
            self.logger.info(f"âœ… ë°±ì—… ìƒì„± ì™„ë£Œ: {filename} ({self.format_size(backup_size)})")
            return True, f"ë°±ì—… ìƒì„± ì™„ë£Œ: {filename} ({self.format_size(backup_size)})"
            
        except Exception as e:
            self.stats["failed_backups"] += 1
            self.logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {traceback.format_exc()}")
            return False, f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}"

    def _verify_backup(self, backup_path: str, expected_files: List[str]) -> bool:
        """ë°±ì—… íŒŒì¼ ê²€ì¦"""
        try:
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                bad_file = zipf.testzip()
                if bad_file:
                    self.logger.error(f"ì†ìƒëœ íŒŒì¼ ë°œê²¬: {bad_file}")
                    return False
                
                zip_files = zipf.namelist()
                for expected_file in expected_files:
                    if expected_file not in zip_files:
                        self.logger.error(f"ì˜ˆìƒ íŒŒì¼ ëˆ„ë½: {expected_file}")
                        return False
                
                return True
        except Exception as e:
            self.logger.error(f"ë°±ì—… ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def list_backups(self) -> List[Dict]:
        """ë°±ì—… ëª©ë¡ ì¡°íšŒ"""
        backups = []
        
        if not self.backup_dir.exists():
            return backups
        
        for file in self.backup_dir.iterdir():
            if file.suffix == '.zip':
                try:
                    stat = file.stat()
                    info = self.get_backup_info(file.name)
                    
                    backups.append({
                        "name": file.name,
                        "size": stat.st_size,
                        "creation_time": datetime.fromtimestamp(stat.st_ctime),
                        "type": info.get("backup_type", "unknown") if info else "unknown",
                        "file_count": info.get("total_files", 0) if info else 0,
                        "valid": self._verify_backup(str(file), info.get("files", []) if info else [])
                    })
                except Exception as e:
                    self.logger.error(f"ë°±ì—… ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {file.name} - {e}")
        
        backups.sort(key=lambda x: x["creation_time"], reverse=True)
        return backups

    def get_backup_info(self, backup_name: str) -> Optional[Dict]:
        """ë°±ì—… ì •ë³´ ì¡°íšŒ"""
        backup_path = self.backup_dir / backup_name
        
        try:
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                if "backup_info.json" in zipf.namelist():
                    info_data = zipf.read("backup_info.json")
                    return json.loads(info_data.decode('utf-8'))
        except Exception as e:
            self.logger.error(f"ë°±ì—… ì •ë³´ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        return None

    def cleanup_old_backups(self) -> int:
        """ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬"""
        try:
            backups = self.list_backups()
            max_backups = self.config.get("max_backups", 30)
            
            if len(backups) <= max_backups:
                return 0
            
            backups_to_delete = backups[max_backups:]
            deleted_count = 0
            
            for backup in backups_to_delete:
                try:
                    backup_path = self.backup_dir / backup["name"]
                    backup_path.unlink()
                    deleted_count += 1
                    self.logger.info(f"ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {backup['name']}")
                except Exception as e:
                    self.logger.error(f"ë°±ì—… ì‚­ì œ ì‹¤íŒ¨: {backup['name']} - {e}")
            
            return deleted_count
            
        except Exception as e:
            self.logger.error(f"ë°±ì—… ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0

    def format_size(self, size_bytes: int) -> str:
        """íŒŒì¼ í¬ê¸° í¬ë§·íŒ…"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f}KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f}MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f}GB"

    def get_stats(self) -> Dict:
        """ë°±ì—… í†µê³„ ì¡°íšŒ"""
        return {
            **self.stats,
            "running": self.running,
            "backup_folder": str(self.backup_dir)
        }

    def start_auto_backup(self) -> bool:
        """ìë™ ë°±ì—… ì‹œì‘"""
        if self.running:
            return False
        
        self.running = True
        self.backup_thread = threading.Thread(target=self._auto_backup_loop, daemon=True)
        self.backup_thread.start()
        
        self.logger.info("ğŸš€ ìë™ ë°±ì—… ì‹œì‘ë¨")
        return True

    def _auto_backup_loop(self):
        """ìë™ ë°±ì—… ë£¨í”„"""
        interval_seconds = self.config.get("backup_interval_hours", 6) * 3600
        
        if self.config.get("backup_on_startup", True):
            self.create_backup("startup")
        
        while self.running:
            try:
                time.sleep(60)
                if not self.running:
                    break
                
                if self.stats["last_backup_time"]:
                    last_backup = datetime.fromisoformat(self.stats["last_backup_time"])
                    if datetime.now() - last_backup < timedelta(seconds=interval_seconds):
                        continue
                
                self.create_backup()
                
            except Exception as e:
                self.logger.error(f"ìë™ ë°±ì—… ë£¨í”„ ì˜¤ë¥˜: {e}")

    def stop_auto_backup(self) -> bool:
        """ìë™ ë°±ì—… ì¤‘ì§€"""
        if not self.running:
            return False
        
        self.logger.info("ìë™ ë°±ì—… ì¤‘ì§€ ì¤‘...")
        self.running = False
        
        if self.backup_thread and self.backup_thread.is_alive():
            self.backup_thread.join(timeout=10)
            if self.backup_thread.is_alive():
                self.logger.warning("ë°±ì—… ìŠ¤ë ˆë“œê°€ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
        
        self.logger.info("âœ… ìë™ ë°±ì—… ì¤‘ì§€ë¨")
        return True

# âœ… Discord ë°±ì—… Cog í´ë˜ìŠ¤
class BackupCog(commands.Cog):
    def __init__(self, bot, backup_system):
        self.bot = bot
        self.backup_system = backup_system

async def setup(bot: commands.Bot):
    backup_system_instance = BackupSystem()
    await bot.add_cog(BackupCog(bot, backup_system_instance))
    backup_system_instance.start_auto_backup()